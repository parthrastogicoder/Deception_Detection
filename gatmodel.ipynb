{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11140308,"sourceType":"datasetVersion","datasetId":6949070},{"sourceId":11407775,"sourceType":"datasetVersion","datasetId":7145947}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport re\nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport os, random, numpy as np, torch\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score\nimport numpy as np\nfrom torch_geometric.data import Data\nfrom collections import defaultdict\nimport json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.metrics import f1_score, accuracy_score\nimport json, re, numpy as np\nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport torch, torch.nn as nn\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GATv2Conv\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.metrics import f1_score, accuracy_score\n\nSEED = 42\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True, warn_only=True)\n\ndef seed_worker(worker_id):\n    worker_seed = SEED + worker_id\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(SEED)\n\ndef clean_message(text):\n    text = text.lower()\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'[^a-z0-9\\s]', '', text)            \n    text = re.sub(r'\\s+', ' ', text).strip()           \n    return text\n\ndef add_history_and_score_delta(input_path, output_path, k=5):\n    with open(input_path, 'r') as f_in, open(output_path, 'w') as f_out:\n        for line in tqdm(f_in, desc=\"Processing games\"):\n            if not line.strip():\n                continue\n\n            game = json.loads(line)\n            game_id = game.get('game_id', 'UNKNOWN')\n\n            sorted_indices = sorted(range(len(game['messages'])),\n                                    key=lambda i: game.get(\"absolute_message_index\", list(range(len(game['messages']))))[i])\n\n            game['messages'] = [game['messages'][i] for i in sorted_indices]\n            game['speakers'] = [game['speakers'][i] for i in sorted_indices]\n            game['receivers'] = [game['receivers'][i] for i in sorted_indices]\n            game['seasons'] = [game['seasons'][i] for i in sorted_indices]\n            game['years'] = [game['years'][i] for i in sorted_indices]\n            if 'absolute_message_index' in game:\n                game['absolute_message_index'] = [game['absolute_message_index'][i] for i in sorted_indices]\n            if 'game_score_delta' in game:\n                game['score_delta'] = [float(game['game_score_delta'][i]) for i in sorted_indices]\n            else:\n                game['score_delta'] = [0.0] * len(game['messages'])\n\n            history_lookup = defaultdict(list)\n            game['history'] = []\n            for i in range(len(game['messages'])):\n                sender = game['speakers'][i]\n                receiver = game['receivers'][i]\n                pair_key = (game_id, sender, receiver)\n\n                cleaned = clean_message(game['messages'][i])\n                game['messages'][i] = cleaned\n\n                last_k = history_lookup[pair_key][-k:]\n                game['history'].append(last_k)\n\n                history_lookup[pair_key].append(cleaned)\n\n            f_out.write(json.dumps(game) + \"\\n\")\n\n\nadd_history_and_score_delta(\"/kaggle/input/deception/train.jsonl\", \"train_with_history_10.jsonl\", k=10)\nadd_history_and_score_delta(\"/kaggle/input/deception/validation.jsonl\", \"val_with_history_10.jsonl\", k=10)\nadd_history_and_score_delta(\"/kaggle/input/deception/test.jsonl\", \"test_with_history_10.jsonl\", k=10)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nCOUNTRY2IDX = {\"russia\":0, \"turkey\":1, \"england\":2, \"france\":3,\n               \"germany\":4, \"italy\":5, \"austria\":6}\nSEASON2IDX  = {\"Spring\":0, \"Fall\":1, \"Winter\":2}\nYEAR_BUCKETS = [1901, 1906, 1911, 1916, 1921]\n\ndef clean_msg(txt: str) -> str:\n    txt = txt.lower()\n    txt = re.sub(r'https?://\\S+|www\\.\\S+', '', txt)\n    txt = re.sub(r'[^a-z0-9\\s]', ' ', txt)\n    return re.sub(r'\\s+', ' ', txt).strip()\n\ndef year_bucket(y: int) -> int:\n    for i, b in enumerate(YEAR_BUCKETS):\n        if y < b:\n            return i\n    return len(YEAR_BUCKETS) - 1\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nbert      = BertModel.from_pretrained(\"bert-base-uncased\").eval().to(device)\n\n@torch.inference_mode()\ndef bert_cls(text: str) -> torch.Tensor:\n    ids = tokenizer(text, return_tensors=\"pt\", truncation=True,\n                    padding=True).to(device)\n    return bert(**ids).last_hidden_state[:, 0, :].squeeze(0).cpu()   # [768]\n\nLEX_PATH = \"/kaggle/input/deception-lexicon/2015_Diplomacy_lexicon.json\"\nwith open(LEX_PATH) as f:\n    _lex = json.load(f)\n\n_lex[\"but\"] = [\"but\"]\n_lex[\"countries\"] = [\"austria\",\"england\",\"france\",\"germany\",\"italy\",\"russia\",\"turkey\"]\n\nLEX_KEYS = list(_lex.keys())\nLEX_CUES = {k:[c.lower() for c in _lex[k]] for k in LEX_KEYS}\n\ntry:\n    import spacy, warnings\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    _nlp = spacy.blank(\"en\")\n    tokenize = lambda txt:[t.text for t in _nlp(txt)]\nexcept Exception:\n    tokenize = lambda txt: re.findall(r\"\\b\\w+\\b\", txt.lower())\n\ndef count_lexicon(msg:str)->np.ndarray:\n    msg_l = msg.lower()\n    tokens = set(tokenize(msg_l))\n    counts=[]\n    for k in LEX_KEYS:\n        total=0\n        for cue in LEX_CUES[k]:\n            total += cue in msg_l if ' ' in cue else cue in tokens\n        counts.append(total)\n    return np.asarray(counts,dtype=np.float32)   # len==10\n\n\n\n\ndef build_game_graph(game_json) -> Data:\n    players = sorted(set(map(str.lower,\n                         game_json[\"speakers\"] + game_json[\"receivers\"])))\n    n = len(players)\n\n    x = torch.zeros(n, len(COUNTRY2IDX))         \n    for i, p in enumerate(players):\n        x[i, COUNTRY2IDX.get(p, 0)] = 1.0\n\n    lie_running      = defaultdict(int)   \n    delta_sum        = defaultdict(float) \n    delta_cnt        = defaultdict(int)   \n\n    e_src, e_dst, e_attr, e_y = [], [], [], []\n\n    abs_idx = game_json.get(\"absolute_message_index\", [])\n    max_abs = max(abs_idx) if abs_idx else 1\n\n    for i, raw in enumerate(game_json[\"messages\"]):\n        s = game_json[\"speakers\"][i].lower()\n        r = game_json[\"receivers\"][i].lower()\n        if s not in players or r not in players:\n            continue\n        s_idx, r_idx = players.index(s), players.index(r)\n\n        clean     = clean_msg(raw)\n        bert_vec  = bert_cls(clean)\n        lex_vec   = torch.from_numpy(count_lexicon(clean))\n\n        lie_so_far = lie_running[s]             \n        lie_feat   = torch.tensor([lie_so_far], dtype=torch.float)\n\n        if delta_cnt[s] == 0:\n            avg_delta = 0.0                      \n        else:\n            avg_delta = delta_sum[s] / delta_cnt[s]\n        power_feat = torch.tensor([avg_delta], dtype=torch.float)\n\n        meta = torch.tensor([\n            SEASON2IDX[game_json[\"seasons\"][i]],\n            year_bucket(int(game_json[\"years\"][i])),\n            game_json[\"absolute_message_index\"][i] / max_abs\n        ])\n\n        e_attr.append(torch.cat([bert_vec,\n                                 lex_vec,\n                                 lie_feat,\n                                 power_feat,\n                                 meta]))\n        e_src.append(s_idx)\n        e_dst.append(r_idx)\n\n        label = 0 if game_json[\"sender_labels\"][i] in (True, \"true\") else 1\n        e_y.append(label)\n\n        lie_running[s] += label\n        delta          = float(game_json[\"score_delta\"][i])  \n        delta_sum[s]  += delta\n        delta_cnt[s]  += 1\n\n    if not e_attr:                    \n        return None\n\n    edge_index = torch.tensor([e_src, e_dst])\n    edge_attr  = torch.stack(e_attr)\n    edge_label = torch.tensor(e_y, dtype=torch.float)\n\n    return Data(\n        x=x,\n        edge_index=edge_index,\n        edge_attr=edge_attr,\n        edge_label=edge_label\n    )\n\nclass DiplomacyGraphDataset(InMemoryDataset):\n    def __init__(self,path:str):\n        super().__init__(\".\")\n        with open(path) as f:\n            data=[build_game_graph(json.loads(l))\n                  for l in f if l.strip()]\n        data=[d for d in data if d is not None]   \n        self.data,self.slices=self.collate(data)\n\nclass LieDetectorGAT(nn.Module):\n    def __init__(self,node_in,edge_in,hid=256,heads=4,layers=3):\n        super().__init__()\n        self.edge_enc=nn.Sequential(nn.Linear(edge_in,hid),nn.ReLU(),\n                                    nn.Linear(hid,hid))\n        self.node_proj=nn.Linear(node_in,hid)\n        self.gats=nn.ModuleList([GATv2Conv(hid,hid//heads,heads=heads,\n                                           edge_dim=hid,add_self_loops=False)\n                                 for _ in range(layers)])\n        self.classifier=nn.Sequential(\n            nn.Linear(hid*2+hid,256),nn.ReLU(),\n            nn.Dropout(0.3),nn.Linear(256,1))\n\n    def forward(self,data):\n        x=self.node_proj(data.x)\n        ea=self.edge_enc(data.edge_attr)\n        for gat in self.gats:\n            x=gat(x,data.edge_index,ea).relu()\n        h_s,h_r=x[data.edge_index[0]],x[data.edge_index[1]]\n        return self.classifier(torch.cat([h_s,h_r,ea],1)).view(-1)\n\n\ntrain_ds=DiplomacyGraphDataset(\"train_with_history_10.jsonl\")\nval_ds  =DiplomacyGraphDataset(\"val_with_history_10.jsonl\")\n\ntrain_loader=DataLoader(train_ds,batch_size=1)\nval_loader  =DataLoader(val_ds,batch_size=1)\n\n\nmodel=LieDetectorGAT(train_ds[0].x.size(1),train_ds[0].edge_attr.size(1)).to(device)\n\nnum_true,num_false=12541,591\ncriterion=nn.BCEWithLogitsLoss(\n    pos_weight=torch.tensor([num_true/num_false],device=device))\nopt=torch.optim.AdamW(model.parameters(),lr=3e-4)\n\n@torch.no_grad()\ndef evaluate(loader):\n    model.eval(); preds,gold=[],[]\n    for data in loader:\n        data=data.to(device)\n        if data.edge_label.numel()==0:   \n            continue\n        prob=torch.sigmoid(model(data))\n        preds+=(prob>0.5).long().cpu().tolist()\n        gold +=data.edge_label.long().cpu().tolist()\n    f1  = f1_score(gold,preds,average=\"macro\")\n    lie = f1_score(gold,preds,pos_label=1,average=\"binary\")\n    acc = accuracy_score(gold,preds)\n    return f1,lie,acc\n\nbest_val_f1 = 0.0\nfor epoch in range(20):\n    model.train(); running = 0.0\n    for data in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        if data.edge_label.numel() == 0:   \n            continue\n        data = data.to(device)\n        opt.zero_grad()\n        loss = criterion(model(data), data.edge_label.to(device))\n        loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step(); running += loss.item()\n\n    tr_f1, tr_lie, tr_acc = evaluate(train_loader)\n    va_f1, va_lie, va_acc = evaluate(val_loader)\n\n    print(f\"\\nEpoch {epoch+1:02d} | \"\n          f\"Loss {running/len(train_loader):.4f} || \"\n          f\"Train F1 {tr_f1:.4f} Acc {tr_acc:.4f} LieF1 {tr_lie:.4f} || \"\n          f\"Val F1 {va_f1:.4f} Acc {va_acc:.4f} LieF1 {va_lie:.4f} || \"\n          )\n\n    if va_f1 > best_val_f1:\n        best_val_f1 = va_f1\n        torch.save(model.state_dict(), \"GATmodel.pt\")\n        print(f\"  ====> Saving new model with best Val F1 (Val F1: {va_f1:.4f}) <====\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:23:55.676990Z","iopub.execute_input":"2025-04-15T16:23:55.677280Z","iopub.status.idle":"2025-04-15T16:27:44.596767Z","shell.execute_reply.started":"2025-04-15T16:23:55.677262Z","shell.execute_reply":"2025-04-15T16:27:44.596031Z"}},"outputs":[{"name":"stderr","text":"Processing games: 189it [00:00, 547.22it/s]\nProcessing games: 21it [00:00, 644.29it/s]\nProcessing games: 42it [00:00, 652.76it/s]\nEpoch 1: 100%|██████████| 184/184 [00:02<00:00, 64.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 01 | Loss 2.6940 || Train F1 0.5196 Acc 0.9544 LieF1 0.0626 || Val F1 0.4899 Acc 0.9605 LieF1 0.0000 || \n  ====> Saving new model with best Val F1 (Val F1: 0.4899) <====\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 184/184 [00:02<00:00, 64.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 02 | Loss 2.5604 || Train F1 0.6026 Acc 0.9245 LieF1 0.2451 || Val F1 0.5356 Acc 0.9386 LieF1 0.1031 || \n  ====> Saving new model with best Val F1 (Val F1: 0.5356) <====\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 184/184 [00:03<00:00, 59.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 03 | Loss 2.6465 || Train F1 0.5961 Acc 0.8964 LieF1 0.2478 || Val F1 0.5702 Acc 0.9089 LieF1 0.1887 || \n  ====> Saving new model with best Val F1 (Val F1: 0.5702) <====\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 184/184 [00:02<00:00, 62.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 04 | Loss 2.5974 || Train F1 0.5745 Acc 0.8523 LieF1 0.2308 || Val F1 0.5432 Acc 0.8658 LieF1 0.1593 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 184/184 [00:02<00:00, 63.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 05 | Loss 2.5077 || Train F1 0.5496 Acc 0.8025 LieF1 0.2120 || Val F1 0.5293 Acc 0.8206 LieF1 0.1589 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 184/184 [00:02<00:00, 62.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 06 | Loss 2.4904 || Train F1 0.5526 Acc 0.8079 LieF1 0.2148 || Val F1 0.5294 Acc 0.8249 LieF1 0.1565 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 184/184 [00:02<00:00, 63.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 07 | Loss 2.4219 || Train F1 0.5622 Acc 0.8202 LieF1 0.2262 || Val F1 0.5313 Acc 0.8319 LieF1 0.1560 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 184/184 [00:02<00:00, 61.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 08 | Loss 2.3027 || Train F1 0.5744 Acc 0.8331 LieF1 0.2426 || Val F1 0.5364 Acc 0.8390 LieF1 0.1618 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 184/184 [00:02<00:00, 62.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 09 | Loss 2.2767 || Train F1 0.5871 Acc 0.8428 LieF1 0.2622 || Val F1 0.5394 Acc 0.8432 LieF1 0.1654 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 184/184 [00:03<00:00, 58.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 | Loss 2.1240 || Train F1 0.6008 Acc 0.8568 LieF1 0.2812 || Val F1 0.5415 Acc 0.8545 LieF1 0.1626 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 184/184 [00:02<00:00, 63.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11 | Loss 1.9473 || Train F1 0.6020 Acc 0.8492 LieF1 0.2883 || Val F1 0.5348 Acc 0.8411 LieF1 0.1573 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 184/184 [00:02<00:00, 63.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12 | Loss 1.7884 || Train F1 0.6400 Acc 0.8961 LieF1 0.3364 || Val F1 0.5433 Acc 0.8806 LieF1 0.1508 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 184/184 [00:02<00:00, 64.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13 | Loss 1.6903 || Train F1 0.6342 Acc 0.8816 LieF1 0.3335 || Val F1 0.5221 Acc 0.8573 LieF1 0.1217 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 184/184 [00:02<00:00, 62.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14 | Loss 1.5853 || Train F1 0.6615 Acc 0.9103 LieF1 0.3714 || Val F1 0.5271 Acc 0.8828 LieF1 0.1170 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 184/184 [00:02<00:00, 63.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15 | Loss 1.4105 || Train F1 0.6771 Acc 0.9148 LieF1 0.4000 || Val F1 0.5378 Acc 0.8905 LieF1 0.1341 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 184/184 [00:02<00:00, 61.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16 | Loss 1.4128 || Train F1 0.6917 Acc 0.9223 LieF1 0.4250 || Val F1 0.5523 Acc 0.8962 LieF1 0.1600 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 184/184 [00:03<00:00, 60.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 17 | Loss 1.3593 || Train F1 0.6900 Acc 0.9164 LieF1 0.4251 || Val F1 0.5379 Acc 0.8849 LieF1 0.1376 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 184/184 [00:02<00:00, 64.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 18 | Loss 1.2888 || Train F1 0.6988 Acc 0.9266 LieF1 0.4369 || Val F1 0.5341 Acc 0.8919 LieF1 0.1257 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 184/184 [00:02<00:00, 64.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 19 | Loss 1.3604 || Train F1 0.7060 Acc 0.9264 LieF1 0.4515 || Val F1 0.5270 Acc 0.8962 LieF1 0.1091 || \n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 184/184 [00:02<00:00, 62.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20 | Loss 1.1790 || Train F1 0.7244 Acc 0.9479 LieF1 0.4763 || Val F1 0.5254 Acc 0.9181 LieF1 0.0938 || \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n\ntest_ds =DiplomacyGraphDataset(\"test_with_history_10.jsonl\")\ntest_loader =DataLoader(test_ds,batch_size=1)\n\nmodel.load_state_dict(torch.load(\"GATmodel.pt\"))\nmodel.eval()\n\n@torch.no_grad()\ndef get_test_predictions_with_meta(loader):\n    all_preds = []\n    all_labels = []\n    misclassified_0 = []  \n    misclassified_1 = []  \n\n    for i, data in enumerate(loader):\n        data = data.to(device)\n        if data.edge_label.numel() == 0:\n            continue\n\n        probs = torch.sigmoid(model(data))\n        pred = (probs > 0.5).long().cpu().tolist()\n        label = data.edge_label.long().cpu().tolist()\n\n        all_preds.extend(pred)\n        all_labels.extend(label)\n\n        idx = 0\n        raw_game = test_ds[i] \n        with open(\"test_with_history_10.jsonl\") as f:\n            for j, line in enumerate(f):\n                if j == i:\n                    raw_game_data = json.loads(line)\n                    break\n\n        for true, guess in zip(label, pred):\n            if true != guess:\n                speaker = raw_game_data[\"speakers\"][idx]\n                receiver = raw_game_data[\"receivers\"][idx]\n                message = raw_game_data[\"messages\"][idx]\n                if true == 0 and len(misclassified_0) < 5:\n                    misclassified_0.append((speaker, receiver, message))\n                elif true == 1 and len(misclassified_1) < 5:\n                    misclassified_1.append((speaker, receiver, message))\n            idx += 1\n\n    return all_labels, all_preds, misclassified_0, misclassified_1\n\n# Run evaluation\ny_true, y_pred, mis_0, mis_1 = get_test_predictions_with_meta(test_loader)\n\nprint(\"\\n--- Classification Report (Test Set) ---\")\nprint(classification_report(y_true, y_pred, target_names=[\"Truthful\", \"Lie\"], digits=3))\n\nprint(\"--- Confusion Matrix (Test Set) ---\")\nprint(confusion_matrix(y_true, y_pred))\n\nlie_precision = precision_score(y_true, y_pred, pos_label=1)\nlie_recall    = recall_score(y_true, y_pred, pos_label=1)\nlie_f1        = f1_score(y_true, y_pred, pos_label=1)\n\nprint(f\"\\n--- Lie Class Metrics ---\")\nprint(f\"Lie Precision: {lie_precision:.4f}\")\nprint(f\"Lie Recall:    {lie_recall:.4f}\")\nprint(f\"Lie F1 Score:  {lie_f1:.4f}\")\n\nprint(\"\\n--- 5 Misclassified Truthful Messages (Predicted Lie) ---\")\nfor s, r, m in mis_0:\n    print(f\"Speaker: {s} | Receiver: {r} | Message: {m}\")\n\nprint(\"\\n--- 5 Misclassified Lie Messages (Predicted Truthful) ---\")\nfor s, r, m in mis_1:\n    print(f\"Speaker: {s} | Receiver: {r} | Message: {m}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:28:03.097390Z","iopub.execute_input":"2025-04-15T16:28:03.097662Z","iopub.status.idle":"2025-04-15T16:28:29.348400Z","shell.execute_reply.started":"2025-04-15T16:28:03.097644Z","shell.execute_reply":"2025-04-15T16:28:29.347455Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3049420735.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"GATmodel.pt\"))\n","output_type":"stream"},{"name":"stdout","text":"\n--- Classification Report (Test Set) ---\n              precision    recall  f1-score   support\n\n    Truthful      0.936     0.854     0.893      2501\n         Lie      0.203     0.388     0.266       240\n\n    accuracy                          0.813      2741\n   macro avg      0.569     0.621     0.580      2741\nweighted avg      0.871     0.813     0.838      2741\n\n--- Confusion Matrix (Test Set) ---\n[[2136  365]\n [ 147   93]]\n\n--- Lie Class Metrics ---\nLie Precision: 0.2031\nLie Recall:    0.3875\nLie F1 Score:  0.2665\n\n--- 5 Misclassified Truthful Messages (Predicted Lie) ---\nSpeaker: france | Receiver: italy | Message: im sure you expect that im coming to attack you and indeed turkey is trying to set me up against you but the way i look at it is that if we were to split your cp turkey would still win i cant let that happen\nSpeaker: england | Receiver: germany | Message: i like to work with people so im open to that plan i figured i would probably stalemate with russia for a while while they figured out what was happening down south\nSpeaker: germany | Receiver: turkey | Message: theyre taken ech now and even if the support into sweden proves russia and england have an alliance there isnt much they can do i agree that im in a bit of a tight spot but i still have full confidence especially with you and austria taking on russia and italy so effectively\nSpeaker: germany | Receiver: france | Message: so given the moves of england this fall it seems clear that theyre attacking both of us i know ive been aggressive to you in the past and i know that chances are you wont believe me or agree to work with me but if you hear me out we both can gain from this and utterly destroy england in the process ill retreat from burgundy this spring and ill agree to not invade any more territories of yours until all of england is destroyed im assuming youre going to build a fleet in brest and if you do so and move bre eng in the spring it would cut any support that fleet could provide and i can kick england out of the north sea from there i can help support you in to the english channel or we could work to convoy an army into the british isles in the next few years i hope you consider\nSpeaker: austria | Receiver: england | Message: doing alright havent heard from many folks yet so i dont have any concrete plans yet\n\n--- 5 Misclassified Lie Messages (Predicted Truthful) ---\nSpeaker: austria | Receiver: italy | Message: id personally rather you didnt because a play around munich is also a play around trieste and vienna ive heard that theres some rancor over in the west and you might be able to profit from a mobbed france if you went that way\nSpeaker: turkey | Receiver: italy | Message: sure understood how about this to fix it tys s tunwes iontun you take back a dot but we push the position forwards toward iberia\nSpeaker: germany | Receiver: russia | Message: hello im looking forward to a fun game as well i usually see good things happen when russia and germany work together so i hope we can both help each other in our initial plans im assuming youre gonna try and attack scandinavia first let me know your thoughts and i look forward to us working well together\nSpeaker: germany | Receiver: france | Message: based on what ive heard so far i have a suspicion england might try for either holland or belgium im gonna go for a pretty conservative start kiel denmark berlin kiel munich hold do you want to agree that i take holland and you take belgium then see where we go from there\nSpeaker: france | Receiver: germany | Message: im considering playing fairly aggressive against england and cutting them off at the pass in 1901 your support for that would be very helpful\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from collections import defaultdict\n\n# -------------------------------\n# Speaker-wise Error Rates\n# -------------------------------\n@torch.no_grad()\ndef get_predictions_with_speaker_meta(loader, raw_jsonl_path):\n    preds, labels, speakers = [], [], []\n\n    # Load raw game lines for speaker metadata\n    with open(raw_jsonl_path, 'r') as f:\n        raw_lines = [json.loads(l) for l in f if l.strip()]\n\n    for i, data in enumerate(loader):\n        data = data.to(device)\n        if data.edge_label.numel() == 0:\n            continue\n\n        prob = torch.sigmoid(model(data))\n        pred = (prob > 0.5).long().cpu().tolist()\n        label = data.edge_label.long().cpu().tolist()\n\n        preds.extend(pred)\n        labels.extend(label)\n\n        # Extract speaker list from the original game line\n        game = raw_lines[i]\n        speakers.extend(game[\"speakers\"])\n\n    return labels, preds, speakers\n\n# Run inference\ny_true, y_pred, speaker_list = get_predictions_with_speaker_meta(test_loader, \"test_with_history_10.jsonl\")\n\n# Calculate speaker-wise error rates\nspeaker_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n\nfor true, pred, speaker in zip(y_true, y_pred, speaker_list):\n    speaker = speaker.lower()\n    speaker_stats[speaker][\"total\"] += 1\n    if true == pred:\n        speaker_stats[speaker][\"correct\"] += 1\n\nprint(\"\\n--- Speaker-wise Error Rates (Test Set) ---\")\nfor speaker in sorted(speaker_stats):\n    correct = speaker_stats[speaker][\"correct\"]\n    total = speaker_stats[speaker][\"total\"]\n    error_rate = 1 - (correct / total) if total > 0 else 0.0\n    print(f\"{speaker:10s} | Total: {total:3d} | Errors: {total - correct:3d} | Error Rate: {error_rate:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T16:06:20.081316Z","iopub.execute_input":"2025-04-15T16:06:20.082060Z","iopub.status.idle":"2025-04-15T16:06:20.401078Z","shell.execute_reply.started":"2025-04-15T16:06:20.082036Z","shell.execute_reply":"2025-04-15T16:06:20.400323Z"}},"outputs":[{"name":"stdout","text":"\n--- Speaker-wise Error Rates (Test Set) ---\naustria    | Total: 107 | Errors:   8 | Error Rate: 0.0748\nengland    | Total: 307 | Errors:  42 | Error Rate: 0.1368\nfrance     | Total: 804 | Errors: 159 | Error Rate: 0.1978\ngermany    | Total: 133 | Errors:  43 | Error Rate: 0.3233\nitaly      | Total:  97 | Errors:   5 | Error Rate: 0.0515\nrussia     | Total: 852 | Errors: 169 | Error Rate: 0.1984\nturkey     | Total: 441 | Errors:  86 | Error Rate: 0.1950\n","output_type":"stream"}],"execution_count":24}]}