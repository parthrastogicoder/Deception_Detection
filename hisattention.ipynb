{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11353803,"sourceType":"datasetVersion","datasetId":7105015},{"sourceId":11381154,"sourceType":"datasetVersion","datasetId":7126171},{"sourceId":11383683,"sourceType":"datasetVersion","datasetId":7127962},{"sourceId":11384678,"sourceType":"datasetVersion","datasetId":7128700},{"sourceId":11387070,"sourceType":"datasetVersion","datasetId":7130556}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":14470.536296,"end_time":"2025-04-13T03:02:15.726109","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-12T23:01:05.189813","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00d98297d17b44e79cab10d78f2bb4b3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06beab60a75f4562a99d50d11f69da30":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07154501326240e5b67fd56d64aeaf99":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"09a6c1d21bc44bbab82425904eebb6db":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0fff850848bb47d3a96faec1c549a1a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1932b6ab683f41efaab5e11b4b503c21","placeholder":"​","style":"IPY_MODEL_647b6202bfe440bcbd87f65c21bcd58d","tabbable":null,"tooltip":null,"value":" 232k/232k [00:00&lt;00:00, 5.45MB/s]"}},"13582a5f5cfb4bc4b5dafb67c1463ba6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1608a644db7a492faa5a3986755e297c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"1932b6ab683f41efaab5e11b4b503c21":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e09ba0f1f3646abb8eaf93ab0f6d39f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65acf90aa81a496981e6f4818da0f0a5","IPY_MODEL_7f6543b533994190ad0ae8e8b0d85400","IPY_MODEL_e315a66edb3d4595aefe14162b2220c9"],"layout":"IPY_MODEL_00d98297d17b44e79cab10d78f2bb4b3","tabbable":null,"tooltip":null}},"20c5fc4d72d64904bc8c865f0a0754ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_4d2417efd43b42b38967b11968c5d7d5","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a52ef593e79d4bae9e9743cedb4a9e61","tabbable":null,"tooltip":null,"value":570}},"2a686137e59947789a1a72f301874aba":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324cdf7d5bdd4aae9e2fc467f8c45018":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e61404469fe43fab5779c511c78c5a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5035b56cb264e6eb8cd495293dde560","IPY_MODEL_980808b76625445ea3244aa412a65169","IPY_MODEL_0fff850848bb47d3a96faec1c549a1a8"],"layout":"IPY_MODEL_ea387fce7a4441cebe64aee4da257db4","tabbable":null,"tooltip":null}},"4264d8a5f1a44f5a978fbafefe1d1b7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7410c7696a684ac88691249d3f48e7f0","placeholder":"​","style":"IPY_MODEL_42bd6e591d97453a8302a68d64dab9da","tabbable":null,"tooltip":null,"value":" 466k/466k [00:00&lt;00:00, 25.7MB/s]"}},"42bd6e591d97453a8302a68d64dab9da":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"43dfd53fd7ec459a8c8eb62b6b629d31":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cfe95494451a43c58707e77890b8d4cf","placeholder":"​","style":"IPY_MODEL_f62099d381534433a7eb05b4b48637c9","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"458290f0942044a4b96adebdbf3c3a49":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496179967952403bba28b5e241da8864":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b875565f979475d8269a4654f4c05c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4d2417efd43b42b38967b11968c5d7d5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5084332a8dc34e1a9c799388ee2421b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_496179967952403bba28b5e241da8864","placeholder":"​","style":"IPY_MODEL_4b875565f979475d8269a4654f4c05c1","tabbable":null,"tooltip":null,"value":" 440M/440M [00:01&lt;00:00, 232MB/s]"}},"52a9d3ad71df4ab599a4082bfdaec12d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53bd1773c35d4408b8fbbbbc11421232":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5447274db4e74025b5d8adfdbab6abfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_458290f0942044a4b96adebdbf3c3a49","placeholder":"​","style":"IPY_MODEL_09a6c1d21bc44bbab82425904eebb6db","tabbable":null,"tooltip":null,"value":" 570/570 [00:00&lt;00:00, 75.9kB/s]"}},"5991f33cabdd423a8defdc019c3947d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_aaa9c2612d984d2b8096684b0ac132cc","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1f20223a8b543689a11d0b8b71d1940","tabbable":null,"tooltip":null,"value":466062}},"5d43b103dd0f428c90180a36fbc1b574":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"647b6202bfe440bcbd87f65c21bcd58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"65acf90aa81a496981e6f4818da0f0a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c6dc6d5bfd794a78b0f4e6ddc923580d","placeholder":"​","style":"IPY_MODEL_1608a644db7a492faa5a3986755e297c","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"69a79b62ca5b43b7829e888cba62d57e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a926cef9d040808dcd6c980d96d8ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90a0a4d7d0f04c16b7ef10211747a080","IPY_MODEL_5991f33cabdd423a8defdc019c3947d3","IPY_MODEL_4264d8a5f1a44f5a978fbafefe1d1b7f"],"layout":"IPY_MODEL_a2402a541c8f444bab1906c517c2c5d8","tabbable":null,"tooltip":null}},"73ea7e1370604c66996ec48bd6c655d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e44289684972489586d724e03127cf68","placeholder":"​","style":"IPY_MODEL_07154501326240e5b67fd56d64aeaf99","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"7410c7696a684ac88691249d3f48e7f0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f6543b533994190ad0ae8e8b0d85400":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_69a79b62ca5b43b7829e888cba62d57e","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6fc7c7c8b7c48c78f38ce5af2ca7721","tabbable":null,"tooltip":null,"value":48}},"8345e3a691264829a00cc987749ae606":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f232701f7c1d4c13bc83545b155f6ce9","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_324cdf7d5bdd4aae9e2fc467f8c45018","tabbable":null,"tooltip":null,"value":440449768}},"835f8e28fc5d4c589c1c08e508bcfc5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43dfd53fd7ec459a8c8eb62b6b629d31","IPY_MODEL_8345e3a691264829a00cc987749ae606","IPY_MODEL_5084332a8dc34e1a9c799388ee2421b8"],"layout":"IPY_MODEL_52a9d3ad71df4ab599a4082bfdaec12d","tabbable":null,"tooltip":null}},"84435ed637924955ae3e917f380d9eec":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"90a0a4d7d0f04c16b7ef10211747a080":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9db5c9784614433b2d41940020e19fc","placeholder":"​","style":"IPY_MODEL_84435ed637924955ae3e917f380d9eec","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"9605e49c78be471aa5f04e067c5daa60":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"980808b76625445ea3244aa412a65169":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_53bd1773c35d4408b8fbbbbc11421232","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13582a5f5cfb4bc4b5dafb67c1463ba6","tabbable":null,"tooltip":null,"value":231508}},"a2402a541c8f444bab1906c517c2c5d8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a52ef593e79d4bae9e9743cedb4a9e61":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aaa9c2612d984d2b8096684b0ac132cc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6dc6d5bfd794a78b0f4e6ddc923580d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9db5c9784614433b2d41940020e19fc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe95494451a43c58707e77890b8d4cf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6d015b429a44219d63629b86f48170":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73ea7e1370604c66996ec48bd6c655d0","IPY_MODEL_20c5fc4d72d64904bc8c865f0a0754ea","IPY_MODEL_5447274db4e74025b5d8adfdbab6abfe"],"layout":"IPY_MODEL_2a686137e59947789a1a72f301874aba","tabbable":null,"tooltip":null}},"e1f20223a8b543689a11d0b8b71d1940":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e315a66edb3d4595aefe14162b2220c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_06beab60a75f4562a99d50d11f69da30","placeholder":"​","style":"IPY_MODEL_5d43b103dd0f428c90180a36fbc1b574","tabbable":null,"tooltip":null,"value":" 48.0/48.0 [00:00&lt;00:00, 5.30kB/s]"}},"e44289684972489586d724e03127cf68":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6fc7c7c8b7c48c78f38ce5af2ca7721":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea387fce7a4441cebe64aee4da257db4":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebdbac3449a449688b64e757079ccb52":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f232701f7c1d4c13bc83545b155f6ce9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5035b56cb264e6eb8cd495293dde560":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_ebdbac3449a449688b64e757079ccb52","placeholder":"​","style":"IPY_MODEL_9605e49c78be471aa5f04e067c5daa60","tabbable":null,"tooltip":null,"value":"vocab.txt: 100%"}},"f62099d381534433a7eb05b4b48637c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ef5d33d9","cell_type":"code","source":"import json\nfrom collections import defaultdict\n\n\ntype_info = defaultdict(set)\nlist_lengths = defaultdict(set)\n\nwith open(\"/kaggle/input/acl-diplomacy/train.jsonl\", 'r') as f:\n    for line in f:\n        entry = json.loads(line)\n        for key, value in entry.items():\n            # Record type\n            type_info[key].add(type(value).__name__)\n\n            \n            if isinstance(value, list):\n                list_lengths[key].add(len(value))\n\n\nprint(\"Key-wise type and list length info:\\n\")\nfor key in sorted(type_info.keys()):\n    print(f\"{key}:\")\n    print(f\"  Types seen: {sorted(type_info[key])}\")\n    if key in list_lengths:\n        print(f\"  List lengths seen: {sorted(list_lengths[key])}\")\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:34:46.165964Z","iopub.execute_input":"2025-04-15T17:34:46.166164Z","iopub.status.idle":"2025-04-15T17:34:46.244297Z","shell.execute_reply.started":"2025-04-15T17:34:46.166139Z","shell.execute_reply":"2025-04-15T17:34:46.243731Z"},"papermill":{"duration":0.008161,"end_time":"2025-04-12T23:01:11.223091","exception":false,"start_time":"2025-04-12T23:01:11.214930","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Key-wise type and list length info:\n\nabsolute_message_index:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\ngame_id:\n  Types seen: ['int']\n\ngame_score:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\ngame_score_delta:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nmessages:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nplayers:\n  Types seen: ['list']\n  List lengths seen: [2]\n\nreceiver_labels:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nreceivers:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nrelative_message_index:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nseasons:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nsender_labels:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nspeakers:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\nyears:\n  Types seen: ['list']\n  List lengths seen: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 78, 81, 86, 87, 90, 95, 96, 98, 99, 104, 113, 119, 120, 123, 130, 133, 134, 135, 136, 139, 145, 148, 150, 151, 155, 157, 161, 166, 189, 197, 205, 208, 215, 283, 321, 366, 435, 457, 471, 480, 511, 656, 675]\n\n","output_type":"stream"}],"execution_count":1},{"id":"9c413078","cell_type":"code","source":"import json\n\n\n\nwith open(\"/kaggle/input/acl-diplomacy/train.jsonl\", 'r') as f:\n    for i in range(3):\n        line = f.readline()\n        if not line:\n            break\n        entry = json.loads(line)\n        print(entry.keys())\n        score_delta = entry.get(\"game_score_delta\")\n        sender_labels = entry.get(\"sender_labels\")\n\n        print(f\"Entry {i+1}:\")\n        print(\"score_delta:\", len(score_delta) if score_delta is not None else \"Missing\")\n        print(\"sender_labels:\", len(sender_labels) if sender_labels is not None else \"Missing\")\n        print()\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:02.619332Z","iopub.execute_input":"2025-04-15T17:35:02.619912Z","iopub.status.idle":"2025-04-15T17:35:02.628462Z","shell.execute_reply.started":"2025-04-15T17:35:02.619886Z","shell.execute_reply":"2025-04-15T17:35:02.627700Z"},"papermill":{"duration":0.008081,"end_time":"2025-04-12T23:01:11.244961","exception":false,"start_time":"2025-04-12T23:01:11.236880","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"dict_keys(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta', 'players', 'game_id'])\nEntry 1:\nscore_delta: 321\nsender_labels: 321\n\ndict_keys(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta', 'players', 'game_id'])\nEntry 2:\nscore_delta: 155\nsender_labels: 155\n\ndict_keys(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta', 'players', 'game_id'])\nEntry 3:\nscore_delta: 87\nsender_labels: 87\n\n","output_type":"stream"}],"execution_count":3},{"id":"b8cad5d1","cell_type":"code","source":"import json\nfrom collections import Counter\n\n\ntrain_file = \"/kaggle/input/acl-diplomacy/train.jsonl\"\nval_file = \"/kaggle/input/acl-diplomacy/validation.jsonl\"\ntest_file = \"/kaggle/input/acl-diplomacy/test.jsonl\"\n\n\ndef count_labels(file_path):\n    counts = Counter()\n    with open(file_path, 'r') as f:\n        for line in f:\n            entry = json.loads(line)\n            label = entry.get(\"sender_labels\", [])\n            for i in label:\n                label_str = str(i).strip().lower()\n                if label_str == \"true\":\n                    counts[\"true\"] += 1\n                elif label_str == \"false\":\n                    counts[\"false\"] += 1\n                else:\n                    counts[\"other\"] += 1\n    return counts\n\ntrain_counts = count_labels(train_file)\nval_counts = count_labels(val_file)\ntest_counts = count_labels(test_file)\n\noverall_counts = train_counts + val_counts + test_counts\n\n\nprint(\"Train label count:\")\nprint(f\"true: {train_counts.get('true', 0)}\")\nprint(f\"false: {train_counts.get('false', 0)}\")\n\nprint()\n\n\nprint(\"Validation label count:\")\nprint(f\"true: {val_counts.get('true', 0)}\")\nprint(f\"false: {val_counts.get('false', 0)}\")\n\nprint()\n\nprint(\"Test label count:\")\nprint(f\"true: {test_counts.get('true', 0)}\")\nprint(f\"false: {test_counts.get('false', 0)}\")\nprint()\n\nprint(\"Overall label count:\")\nprint(f\"true: {overall_counts.get('true', 0)}\")\nprint(f\"false: {overall_counts.get('false', 0)}\")\n\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:07.723086Z","iopub.execute_input":"2025-04-15T17:35:07.723580Z","iopub.status.idle":"2025-04-15T17:35:07.786489Z","shell.execute_reply.started":"2025-04-15T17:35:07.723553Z","shell.execute_reply":"2025-04-15T17:35:07.785931Z"},"papermill":{"duration":0.008318,"end_time":"2025-04-12T23:01:11.256391","exception":false,"start_time":"2025-04-12T23:01:11.248073","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Train label count:\ntrue: 12541\nfalse: 591\n\nValidation label count:\ntrue: 1360\nfalse: 56\n\nTest label count:\ntrue: 2501\nfalse: 240\n\nOverall label count:\ntrue: 16402\nfalse: 887\n\n","output_type":"stream"}],"execution_count":4},{"id":"a52b425e","cell_type":"code","source":"import json\nimport re\nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport json\nimport re\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\ndef clean_message(text):\n    text = text.lower()\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  \n    text = re.sub(r'[^a-z0-9\\s]', '', text)          \n    text = re.sub(r'\\s+', ' ', text).strip()          \n    return text\n\ndef add_history_to_jsonl(input_path, output_path, k=5):\n    with open(input_path, 'r') as f_in, open(output_path, 'w') as f_out:\n        for line in tqdm(f_in, desc=\"Processing games\"):\n            if not line.strip():\n                continue\n\n            game = json.loads(line)\n            game_id = game.get('game_id', 'UNKNOWN')\n\n            messages = game['messages']\n            speakers = game['speakers']\n            receivers = game['receivers']\n\n    \n            history_lookup = defaultdict(list)\n\n            game['history'] = []\n\n            for i in range(len(messages)):\n                sender = speakers[i]\n                receiver = receivers[i]\n                pair_key = (game_id, sender, receiver)\n\n                \n                cleaned = clean_message(messages[i])\n                game['messages'][i] = cleaned\n\n              \n                last_k = history_lookup[pair_key][-k:]\n                game['history'].append(last_k)\n\n               \n                history_lookup[pair_key].append(cleaned)\n\n            \n            f_out.write(json.dumps(game) + \"\\n\")\n\n\nadd_history_to_jsonl(\"/kaggle/input/acl-diplomacy/train.jsonl\", \"train_with_history_10.jsonl\", k=10)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:13.804662Z","iopub.execute_input":"2025-04-15T17:35:13.805107Z","iopub.status.idle":"2025-04-15T17:35:14.109664Z","shell.execute_reply.started":"2025-04-15T17:35:13.805083Z","shell.execute_reply":"2025-04-15T17:35:14.109054Z"},"papermill":{"duration":0.008165,"end_time":"2025-04-12T23:01:11.278053","exception":false,"start_time":"2025-04-12T23:01:11.269888","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Processing games: 189it [00:00, 665.82it/s]\n","output_type":"stream"}],"execution_count":5},{"id":"ca18cff6","cell_type":"code","source":"add_history_to_jsonl(\"/kaggle/input/acl-diplomacy/validation.jsonl\", \"val_with_history_10.jsonl\", k=10)\nadd_history_to_jsonl(\"/kaggle/input/acl-diplomacy/test.jsonl\", \"test_with_history_10.jsonl\", k=10)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:16.007690Z","iopub.execute_input":"2025-04-15T17:35:16.008319Z","iopub.status.idle":"2025-04-15T17:35:16.095642Z","shell.execute_reply.started":"2025-04-15T17:35:16.008297Z","shell.execute_reply":"2025-04-15T17:35:16.095058Z"},"papermill":{"duration":0.007231,"end_time":"2025-04-12T23:01:11.299317","exception":false,"start_time":"2025-04-12T23:01:11.292086","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"Processing games: 21it [00:00, 771.12it/s]\nProcessing games: 42it [00:00, 813.39it/s]\n","output_type":"stream"}],"execution_count":6},{"id":"d1e7c2eb","cell_type":"code","source":"import json\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, accuracy_score\nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:18.687858Z","iopub.execute_input":"2025-04-15T17:35:18.688467Z","iopub.status.idle":"2025-04-15T17:35:42.992136Z","shell.execute_reply.started":"2025-04-15T17:35:18.688408Z","shell.execute_reply":"2025-04-15T17:35:42.991599Z"},"papermill":{"duration":42.408699,"end_time":"2025-04-12T23:01:53.721417","exception":false,"start_time":"2025-04-12T23:01:11.312718","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"2025-04-15 17:35:31.654753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744738531.847163      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744738531.901981      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"id":"fcf3896a-a2d3-4779-b5c5-4dcfe503a99f","cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=50):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n      \n        pe = torch.zeros(max_len, d_model) \n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        if d_model % 2 == 1:\n           \n            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n        else:\n            pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0) \n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n       \n        x = x + self.pe[:, :x.size(1)]\n        return self.dropout(x)\n\n\nclass GameStateEncoder(nn.Module):\n    def __init__(self, season_vocab_size, year_vocab_size, out_dim=32):\n        super(GameStateEncoder, self).__init__()\n        \n        input_dim = 2 + season_vocab_size + year_vocab_size\n        self.fc = nn.Sequential(\n            nn.Linear(input_dim, out_dim),\n            nn.ReLU()\n        )\n    \n    def forward(self, game_features):\n        \n        return self.fc(game_features)\n\nclass HistoryEncoderTransformer(nn.Module):\n    def __init__(self, hidden_dim=768, num_layers=2, num_heads=8, dropout=0.1):\n        super(HistoryEncoderTransformer, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.pos_encoder = PositionalEncoding(hidden_dim, dropout=dropout, max_len=20)  \n\n    def forward(self, history_texts_batch):\n        \n        device = next(self.parameters()).device\n        all_bert_embeddings = []\n        lengths = []\n\n        for history in history_texts_batch:\n            if len(history) == 0:\n            \n                history = [\"\"]\n           \n            inputs = self.tokenizer(history, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n\n            with torch.no_grad():\n                outputs = self.bert(**inputs)\n        \n            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n            all_bert_embeddings.append(cls_embeddings)\n            lengths.append(cls_embeddings.size(0))\n        \n      \n        padded = nn.utils.rnn.pad_sequence(all_bert_embeddings, batch_first=True) \n        max_len = padded.size(1)\n        attn_mask = torch.zeros(padded.size(0), max_len, dtype=torch.bool, device=device)\n        for i, l in enumerate(lengths):\n            if l < max_len:\n                attn_mask[i, l:] = True\n\n    \n        padded = self.pos_encoder(padded)\n      \n        transformer_out = self.transformer_encoder(padded, src_key_padding_mask=attn_mask)\n    \n        pooled = []\n        for i in range(transformer_out.size(0)):\n            valid_tokens = transformer_out[i, :lengths[i], :]\n            pooled.append(valid_tokens.mean(dim=0))\n        history_encoding = torch.stack(pooled, dim=0) \n        return history_encoding\n\nclass FusionAttention(nn.Module):\n    def __init__(self, input_dim, num_heads=2):\n        super(FusionAttention, self).__init__()\n    \n        self.attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True)\n        \n        self.pooling_query = nn.Parameter(torch.randn(1, 1, input_dim))\n    \n    def forward(self, features):\n       \n        attn_out, _ = self.attn(features, features, features)\n    \n        query = self.pooling_query.expand(attn_out.size(0), -1, -1) \n     \n        attn_weights = torch.bmm(query, attn_out.transpose(1, 2)) \n        attn_weights = torch.softmax(attn_weights, dim=-1) \n        \n        fused_vector = torch.bmm(attn_weights, attn_out).squeeze(1) \n        return fused_vector\n\n\nclass DeceptionClassifier(nn.Module):\n    def __init__(self, fused_dim):\n        super(DeceptionClassifier, self).__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(fused_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1)\n        )\n    \n    def forward(self, fused_vector):\n        logits = self.classifier(fused_vector)\n        return logits\n\n\nclass MultiModalDeceptionModel(nn.Module):\n    def __init__(self, season_vocab_size=3, year_vocab_size=5,\n                 game_state_out_dim=32, fusion_dim=768):\n        super(MultiModalDeceptionModel, self).__init__()\n   \n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        \n\n        self.game_encoder = GameStateEncoder(season_vocab_size, year_vocab_size, out_dim=game_state_out_dim)\n\n        self.sender_embedding = nn.Embedding(num_embeddings=7, embedding_dim=16)\n        self.receiver_embedding = nn.Embedding(num_embeddings=7, embedding_dim=16)\n        self.sender_receiver_proj = nn.Linear(64, self.tokenizer.model_max_length if hasattr(self.tokenizer, 'model_max_length') else fusion_dim)\n        self.proj_to_text_dim = nn.Linear(self.sender_receiver_proj.out_features, fusion_dim)\n        self.history_encoder = HistoryEncoderTransformer(hidden_dim=fusion_dim)\n       \n        self.text_feature_dim = fusion_dim  # 768\n        self.fusion_attention = FusionAttention(input_dim=self.text_feature_dim, num_heads=2)\n        \n    \n        self.classifier = DeceptionClassifier(fused_dim=self.text_feature_dim)\n    \n    def forward(self, current_message, game_state_features, history_texts, sender_ids, receiver_ids):\n        device = next(self.parameters()).device\n\n        inputs = self.tokenizer(current_message, return_tensors=\"pt\", truncation=True, padding=True)\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        text_outputs = self.bert(**inputs)\n        text_vector = text_outputs.last_hidden_state[:, 0, :] \n    \n        \n        game_vector_raw = self.game_encoder(game_state_features)  \n    \n     \n        sender_emb = self.sender_embedding(sender_ids)   \n        receiver_emb = self.receiver_embedding(receiver_ids) \n        combined_game = torch.cat([game_vector_raw, sender_emb, receiver_emb], dim=1) \n       \n        game_vector_proj = self.sender_receiver_proj(combined_game)\n        game_vector = self.proj_to_text_dim(game_vector_proj)\n    \n       \n        history_vector = self.history_encoder(history_texts)  \n    \n        \n        fusion_input = torch.stack([text_vector, game_vector, history_vector], dim=1)\n    \n\n        fused_vector = self.fusion_attention(fusion_input)  \n    \n        logits = self.classifier(fused_vector) \n        return logits\n\nclass DeceptionDataset(Dataset):\n    def __init__(self, jsonl_file, season_to_idx=None, year_buckets=None, country_to_idx=None):\n        self.samples = []\n        self.season_to_idx = season_to_idx or {\"Spring\": 0, \"Fall\": 1, \"Winter\": 2}\n        self.year_buckets = year_buckets or [1901, 1906, 1911, 1916, 1921]\n        self.country_to_idx = country_to_idx or {\"russia\":0, \"turkey\":1, \"england\":2, \"france\":3, \"germany\":4, \"italy\":5, \"austria\":6}\n        \n        with open(jsonl_file, 'r') as f:\n            for line in f:\n                if not line.strip():\n                    continue\n                game = json.loads(line)\n                num_messages = len(game['messages'])\n                for i in range(num_messages):\n                    sample = {}\n                \n                    sample['current_message'] = game['messages'][i]\n                    \n        \n                    try:\n                        game_score = float(game['game_score'][i])\n                    except:\n                        game_score = 0.0\n                    try:\n                        score_delta = float(game['game_score_delta'][i])\n                    except:\n                        score_delta = 0.0\n                    \n                \n                    season = game['seasons'][i]\n                    season_vec = [0] * len(self.season_to_idx)\n                    if season in self.season_to_idx:\n                        season_vec[self.season_to_idx[season]] = 1\n                    \n                \n                    year = int(game['years'][i])\n                    year_bucket = self.bucket_year(year)\n                    year_vec = [0] * (len(self.year_buckets))\n                    year_vec[year_bucket] = 1\n                    \n                  \n                    game_state = [game_score, score_delta] + season_vec + year_vec\n                    sample['game_state_features'] = torch.tensor(game_state, dtype=torch.float)\n                    \n                   \n                    sample['history'] = game['history'][i]\n                    \n                    \n                    sender_str = game['speakers'][i].lower()\n                    receiver_str = game['receivers'][i].lower()\n                    sample['sender'] = torch.tensor(self.country_to_idx.get(sender_str, 0), dtype=torch.long)\n                    sample['receiver'] = torch.tensor(self.country_to_idx.get(receiver_str, 0), dtype=torch.long)\n                    \n                    label_raw = game['sender_labels'][i]\n                    label = 0 if label_raw is True or label_raw == \"true\" else 1\n                    sample['label'] = torch.tensor(label, dtype=torch.float)\n                    \n                    self.samples.append(sample)\n    \n    def bucket_year(self, year):\n        for idx, bound in enumerate(self.year_buckets):\n            if year < bound:\n                return idx\n        return len(self.year_buckets) - 1\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        return self.samples[idx]\n\ndef collate_fn(batch):\n    current_messages = [sample['current_message'] for sample in batch]\n    game_states = torch.stack([sample['game_state_features'] for sample in batch])  # [batch, dim]\n    histories = [sample['history'] for sample in batch]  \n    sender_ids = torch.stack([sample['sender'] for sample in batch])\n    receiver_ids = torch.stack([sample['receiver'] for sample in batch])\n    labels = torch.stack([sample['label'] for sample in batch])\n    return current_messages, game_states, histories, sender_ids, receiver_ids, labels\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:35:43.737012Z","iopub.execute_input":"2025-04-15T17:35:43.738084Z","iopub.status.idle":"2025-04-15T17:35:43.768147Z","shell.execute_reply.started":"2025-04-15T17:35:43.738055Z","shell.execute_reply":"2025-04-15T17:35:43.767340Z"}},"outputs":[],"execution_count":8},{"id":"af8ea286","cell_type":"code","source":"\n\nmodel = MultiModalDeceptionModel(season_vocab_size=3, year_vocab_size=5,\n                                 game_state_out_dim=32, fusion_dim=768)\nmodel.to(device)\n\n\ntrain_dataset = DeceptionDataset(\"train_with_history_10.jsonl\")\nval_dataset   = DeceptionDataset(\"val_with_history_10.jsonl\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n\nnum_true = 12541\nnum_false = 591\npos_weight_value = num_true / num_false\npos_weight = torch.tensor([pos_weight_value]).to(device)\nprint(f\"Class counts -> True: {num_true}, False: {num_false}\")\nprint(f\"Computed pos_weight for BCEWithLogitsLoss: {pos_weight_value:.4f}\")\n\nlr = 1e-5\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\nbest_f1 = 0.0\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)\n\nbest_f1 = 0.0\n\nmodel.train()\nfor epoch in range(10):\n    train_losses = []\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n        current_messages, game_states, histories, sender_ids, receiver_ids, labels = batch\n        optimizer.zero_grad()\n        \n        game_states = game_states.to(device)\n        sender_ids = sender_ids.to(device)\n        receiver_ids = receiver_ids.to(device)\n        labels = labels.to(device)\n        \n        logits = model(current_messages, game_states, histories, sender_ids, receiver_ids)\n        loss = criterion(logits.view(-1), labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        train_losses.append(loss.item())\n    \n    avg_train_loss = np.mean(train_losses)\n    \n    # Validation\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n            current_messages, game_states, histories, sender_ids, receiver_ids, labels = batch\n            game_states = game_states.to(device)\n            sender_ids = sender_ids.to(device)\n            receiver_ids = receiver_ids.to(device)\n            labels = labels.to(device)\n            logits = model(current_messages, game_states, histories, sender_ids, receiver_ids)\n            prob = torch.sigmoid(logits.view(-1))\n            preds = (prob > 0.5).long()\n            all_preds.extend(preds.tolist())\n            all_labels.extend(labels.long().tolist())\n    \n    val_acc = accuracy_score(all_labels, all_preds)\n    val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n    print(f\"\\nEpoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Acc = {val_acc:.4f} | Val F1 = {val_f1:.4f}\")\n    \n    scheduler.step(avg_train_loss)\n    \n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        torch.save(model.state_dict(), \"best_model_attention2.pt\")\n        print(f\" Saved new best model (F1 = {val_f1:.4f}) at epoch {epoch+1}\")\n    \n    model.train()\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T21:51:55.156973Z","iopub.execute_input":"2025-04-14T21:51:55.157232Z","iopub.status.idle":"2025-04-15T00:01:39.821316Z","shell.execute_reply.started":"2025-04-14T21:51:55.157214Z","shell.execute_reply":"2025-04-15T00:01:39.820500Z"},"papermill":{"duration":0.024205,"end_time":"2025-04-12T23:01:53.749309","exception":false,"start_time":"2025-04-12T23:01:53.725104","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Class counts -> True: 12541, False: 591\nComputed pos_weight for BCEWithLogitsLoss: 21.2200\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 Training: 100%|██████████| 821/821 [12:18<00:00,  1.11it/s]\nEpoch 1 Validation: 100%|██████████| 89/89 [00:52<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: Train Loss = 2.0546 | Val Acc = 0.9569 | Val F1 = 0.4890\n Saved new best model (F1 = 0.4890) at epoch 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 Training: 100%|██████████| 821/821 [12:00<00:00,  1.14it/s]\nEpoch 2 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: Train Loss = 2.3864 | Val Acc = 0.9576 | Val F1 = 0.5053\n Saved new best model (F1 = 0.5053) at epoch 2\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 Training: 100%|██████████| 821/821 [11:57<00:00,  1.14it/s]\nEpoch 3 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3: Train Loss = 2.3605 | Val Acc = 0.9597 | Val F1 = 0.5225\n Saved new best model (F1 = 0.5225) at epoch 3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 Training: 100%|██████████| 821/821 [11:54<00:00,  1.15it/s]\nEpoch 4 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4: Train Loss = 2.2733 | Val Acc = 0.9590 | Val F1 = 0.6079\n Saved new best model (F1 = 0.6079) at epoch 4\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 Training: 100%|██████████| 821/821 [12:12<00:00,  1.12it/s]\nEpoch 5 Validation: 100%|██████████| 89/89 [00:53<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5: Train Loss = 2.0693 | Val Acc = 0.9520 | Val F1 = 0.5626\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 Training: 100%|██████████| 821/821 [12:14<00:00,  1.12it/s]\nEpoch 6 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6: Train Loss = 1.7672 | Val Acc = 0.9484 | Val F1 = 0.5672\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 Training: 100%|██████████| 821/821 [11:58<00:00,  1.14it/s]\nEpoch 7 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7: Train Loss = 1.6262 | Val Acc = 0.9294 | Val F1 = 0.5430\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 Training: 100%|██████████| 821/821 [11:57<00:00,  1.14it/s]\nEpoch 8 Validation: 100%|██████████| 89/89 [00:51<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8: Train Loss = 1.5442 | Val Acc = 0.9477 | Val F1 = 0.5563\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 Training: 100%|██████████| 821/821 [11:59<00:00,  1.14it/s]\nEpoch 9 Validation: 100%|██████████| 89/89 [00:53<00:00,  1.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9: Train Loss = 1.3868 | Val Acc = 0.9541 | Val F1 = 0.5661\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 Training: 100%|██████████| 821/821 [12:19<00:00,  1.11it/s]\nEpoch 10 Validation: 100%|██████████| 89/89 [00:53<00:00,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10: Train Loss = 1.2362 | Val Acc = 0.9470 | Val F1 = 0.5553\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"id":"40c3eb70","cell_type":"code","source":"#sfsdfsdfdsfhghhghfggfdfgggghhhhghhfghfghfghfghfghfghfhgjghjhhgjfgjhfgfgdgdfgdfgdfgdfghghfjkhkjhkhkjhhghghg","metadata":{"papermill":{"duration":0.016266,"end_time":"2025-04-12T23:01:53.769229","exception":false,"start_time":"2025-04-12T23:01:53.752963","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9f22483f","cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel = MultiModalDeceptionModel(season_vocab_size=3, year_vocab_size=5,\n                                 game_state_out_dim=32, fusion_dim=768)\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/attention-tranformer-all-embed/best_model_attention2 (1).pt\"))\nmodel.eval()\ntest_dataset   = DeceptionDataset(\"/kaggle/working/test_with_history_10.jsonl\")\n\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Test Evaluation\"):\n        current_messages, game_states, histories, sender_ids, receiver_ids, labels = batch\n        \n   \n        game_states = game_states.to(device)\n        sender_ids = sender_ids.to(device)\n        receiver_ids = receiver_ids.to(device)\n        labels = labels.to(device)\n        \n        logits = model(current_messages, game_states, histories, sender_ids, receiver_ids)\n        prob = torch.sigmoid(logits.view(-1))\n        preds = (prob > 0.5).long()\n        \n        all_preds.extend(preds.tolist())\n        all_labels.extend(labels.long().tolist())\n\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(all_labels, all_preds)\nprint(\"Final Confusion Matrix:\")\n\nprint(cm)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-15T17:35:56.795281Z","iopub.execute_input":"2025-04-15T17:35:56.795986Z","iopub.status.idle":"2025-04-15T17:37:39.733143Z","shell.execute_reply.started":"2025-04-15T17:35:56.795952Z","shell.execute_reply":"2025-04-15T17:37:39.732495Z"},"papermill":{"duration":2.401978,"end_time":"2025-04-13T03:02:10.399281","exception":false,"start_time":"2025-04-13T03:02:07.997303","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e74ef2d34e0345f9a8c3156a2cab34f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9651c1c7f134a729cee139fbc7d94b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db828f603e314c6a861f1e3ba2800f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a598abf98fe947fe98137407c1f7eb42"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4729ccffa40404ea38f1f1cced10ce2"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/2741313910.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/attention-tranformer-all-embed/best_model_attention2 (1).pt\"))\nTest Evaluation:   0%|          | 0/172 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\nTest Evaluation: 100%|██████████| 172/172 [01:31<00:00,  1.89it/s]","output_type":"stream"},{"name":"stdout","text":"Final Confusion Matrix:\n[[2328  173]\n [ 189   51]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"id":"ebcc7a60-8a29-4058-b7c9-62f1d879b018","cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\naccuracy = accuracy_score(all_labels, all_preds)\n\nprecision_macro = precision_score(all_labels, all_preds, average=\"macro\")\nrecall_macro = recall_score(all_labels, all_preds, average=\"macro\")\n\nf1_macro = f1_score(all_labels, all_preds, average=\"macro\")\nf1_per_class = f1_score(all_labels, all_preds, average=None, labels=[0, 1])\n\n\nprint(f\"Accuracy       : {accuracy:.4f}\")\nprint(f\"Precision (avg): {precision_macro:.4f}\")\nprint(f\"Recall    (avg): {recall_macro:.4f}\")\nprint(f\"F1 Score  (avg): {f1_macro:.4f}\")\nprint(f\"F1 Score (class 0): {f1_per_class[0]:.4f}\")\nprint(f\"F1 Score (class 1): {f1_per_class[1]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T17:37:41.590855Z","iopub.execute_input":"2025-04-15T17:37:41.591130Z","iopub.status.idle":"2025-04-15T17:37:41.618532Z","shell.execute_reply.started":"2025-04-15T17:37:41.591111Z","shell.execute_reply":"2025-04-15T17:37:41.617865Z"}},"outputs":[{"name":"stdout","text":"Accuracy       : 0.8679\nPrecision (avg): 0.5763\nRecall    (avg): 0.5717\nF1 Score  (avg): 0.5738\nF1 Score (class 0): 0.9279\nF1 Score (class 1): 0.2198\n","output_type":"stream"}],"execution_count":11}]}